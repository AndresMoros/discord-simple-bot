import discord
from discord import app_commands
from discord.ext import commands
import google.generativeai as genai
import os
import asyncio
from datetime import datetime

# Configuraci√≥n
DISCORD_TOKEN = os.environ['DISCORD_TOKEN']
GEMINI_API_KEY = os.environ['GEMINI_API_KEY']

# Configurar Gemini
genai.configure(api_key=GEMINI_API_KEY)

intents = discord.Intents.default()
intents.message_content = True

bot = commands.Bot(command_prefix='!', intents=intents)

class GeminiManager:
    def __init__(self):
        # USAR GEMINI 2.0 FLASH
        self.model = genai.GenerativeModel('gemini-2.0-flash')
        self.chat = self.model.start_chat(history=[])
        self.total_requests = 0

    async def get_response(self, prompt, max_tokens=None):
        try:
            self.total_requests += 1
            print(f"üì® Enviando: {prompt[:50]}...")
            
            # Configuraci√≥n de generaci√≥n
            generation_config = {}
            if max_tokens:
                generation_config["max_output_tokens"] = max_tokens
            
            response = await asyncio.to_thread(
                self.model.generate_content, 
                prompt,
                generation_config=generation_config or None
            )
            
            if response.text:
                print(f"‚úÖ Respuesta recibida ({len(response.text)} caracteres)")
                return response.text
            else:
                return "‚ùå No recib√≠ respuesta. Intenta de nuevo."
                
        except Exception as e:
            print(f"‚ùå Error con Gemini: {e}")
            return "‚ùå Error temporal. Intenta m√°s tarde."

gemini_mgr = GeminiManager()

@bot.event
async def on_ready():
    print(f'‚úÖ Bot conectado como {bot.user}')
    print('ü§ñ Usando Google Gemini 2.0 Flash')
    
    try:
        synced = await bot.tree.sync()
        print(f"‚úÖ Sincronizados {len(synced)} comandos slash")
    except Exception as e:
        print(f"‚ùå Error sincronizando comandos: {e}")

def split_long_message(message, max_length=2000):
    """Divide mensajes largos en chunks de m√°ximo max_length caracteres"""
    if len(message) <= max_length:
        return [message]
    
    chunks = []
    current_chunk = ""
    
    # Dividir por oraciones para no cortar palabras
    sentences = message.split('. ')
    for sentence in sentences:
        # Si la oraci√≥n sola es demasiado larga, dividirla por palabras
        if len(sentence) > max_length - 50:
            words = sentence.split(' ')
            for word in words:
                if len(current_chunk) + len(word) + 1 > max_length:
                    if current_chunk:
                        chunks.append(current_chunk)
                        current_chunk = word
                else:
                    if current_chunk:
                        current_chunk += " " + word
                    else:
                        current_chunk = word
        else:
            # Si agregar esta oraci√≥n excede el l√≠mite, guardar el chunk actual
            if len(current_chunk) + len(sentence) + 2 > max_length:
                if current_chunk:
                    chunks.append(current_chunk)
                    current_chunk = sentence
            else:
                # Agregar la oraci√≥n al chunk actual
                if current_chunk:
                    current_chunk += ". " + sentence
                else:
                    current_chunk = sentence
    
    # Agregar el √∫ltimo chunk si queda algo
    if current_chunk:
        chunks.append(current_chunk)
    
    # Asegurar que NING√öN chunk exceda el l√≠mite
    final_chunks = []
    for chunk in chunks:
        # Si el chunk es muy largo, dividirlo forzosamente
        while len(chunk) > max_length:
            # Encontrar un punto de corte natural cerca del l√≠mite
            cut_point = max_length
            for i in range(max_length, max(0, max_length-100), -1):
                if chunk[i] in ['.', '!', '?', ' ', '\n']:
                    cut_point = i + 1
                    break
            
            final_chunks.append(chunk[:cut_point])
            chunk = chunk[cut_point:]
        
        if chunk.strip():  # Solo agregar si no est√° vac√≠o
            final_chunks.append(chunk)
    
    return final_chunks

def ensure_short_response(response, max_length=1500):
    """Asegura que la respuesta no exceda el l√≠mite de un mensaje"""
    if len(response) <= max_length:
        return response
    
    # Truncar inteligentemente en un punto natural
    truncated = response[:max_length]
    
    # Encontrar el √∫ltimo punto completo
    last_period = truncated.rfind('.')
    if last_period > max_length * 0.7:  # Si hay un punto en el 70% final
        return truncated[:last_period + 1] + ".. (respuesta truncada)"
    else:
        return truncated + ".. (respuesta truncada)"

def create_markdown_file(pregunta, respuesta, username):
    """Crea un archivo Markdown con formato bonito"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    # Soluci√≥n simple: usar ASCII solamente para evitar problemas
    import unicodedata
    respuesta_limpia = unicodedata.normalize('NFKD', respuesta).encode('ascii', 'ignore').decode('ascii')
    
    markdown_content = f"""# ü§ñ Respuesta de Gemini

**Pregunta:**  
{pregunta}

**Usuario:** {username}  
**Fecha:** {timestamp}  
**Modelo:** Gemini 2.0 Flash

---

## üìù Respuesta:

{respuesta_limpia}
"""
    
    filename = f"respuesta_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    
    with open(filename, "w", encoding="utf-8") as f:
        f.write(markdown_content)
    
    return filename

@bot.tree.command(name="ask", description="Haz una pregunta al bot con IA (respuesta completa)")
@app_commands.describe(pregunta="Escribe tu pregunta aqu√≠")
async def ask(interaction: discord.Interaction, pregunta: str):
    if len(pregunta) > 500:
        await interaction.response.send_message("‚ùå La pregunta es muy larga. M√°ximo 500 caracteres.", ephemeral=True)
        return
    
    await interaction.response.defer()
    
    try:
        respuesta = await gemini_mgr.get_response(pregunta)
        
        print(f"üìè Longitud de respuesta: {len(respuesta)} caracteres")
        
        # DECISI√ìN INTELIGENTE: ¬øArchivo o mensajes?
        usar_archivo = False
        
        # 1. Si es MUY largo (>8000 caracteres) ‚Üí Archivo
        if len(respuesta) > 8000:
            usar_archivo = True
            print("üîç Decisi√≥n: Archivo (muy largo)")
        
        # 2. Si tiene estructura compleja (muchos puntos, listas) ‚Üí Archivo
        elif respuesta.count('.') > 30 or respuesta.count('-') > 20:
            usar_archivo = True
            print("üîç Decisi√≥n: Archivo (estructura compleja)")
        
        # 3. Si es moderadamente largo pero bien estructurado ‚Üí Dividir en mensajes
        else:
            # Dividir respuesta normal
            chunks = split_long_message(respuesta)
            chunks = chunks[:4]  # M√°ximo 4 chunks + mensaje inicial = 5 total
            
            print(f"üì¶ N√∫mero de chunks: {len(chunks)}")
            
            # Verificar si la divisi√≥n es eficiente
            if len(chunks) > 3 and len(respuesta) > 4000:
                usar_archivo = True
                print("üîç Decisi√≥n: Archivo (mala divisi√≥n)")
            else:
                # Enviar como mensajes normales
                for i, chunk in enumerate(chunks):
                    print(f"Chunk {i}: {len(chunk)} caracteres")
                    if len(chunk) > 2000:
                        chunks[i] = chunk[:2000]
                
                # Enviar primer chunk
                await interaction.followup.send(f"ü§ñ {chunks[0]}")
                
                # Enviar chunks adicionales con delays
                for chunk in chunks[1:]:
                    await asyncio.sleep(0.5)
                    if chunk.strip():
                        await interaction.followup.send(chunk)
                
                # Notificar SOLO si fue significativamente truncado
                if len(respuesta) > sum(len(chunk) for chunk in chunks) * 1.2:
                    await interaction.followup.send("‚ÑπÔ∏è *La respuesta fue ligeramente acortada.*")
                return
        
        # Si decidimos usar archivo
        if usar_archivo:
            await interaction.followup.send("üìù Creando documento con respuesta completa...")
            
            filename = create_markdown_file(pregunta, respuesta, interaction.user.name)
            
            await interaction.followup.send(
                file=discord.File(filename),
                content=f"üìÑ **Respuesta completa para:** {pregunta[:80]}..."
            )
            
            await asyncio.sleep(2)
            if os.path.exists(filename):
                os.remove(filename)
            
    except Exception as e:
        print(f"‚ùå Error en comando ask: {e}")
        import traceback
        traceback.print_exc()
        await interaction.followup.send("‚ùå Error al procesar tu pregunta. Intenta m√°s tarde.")

@bot.tree.command(name="quick", description="Haz una pregunta con respuesta r√°pida y corta (1 mensaje m√°ximo)")
@app_commands.describe(pregunta="Escribe tu pregunta para respuesta r√°pida")
async def quick(interaction: discord.Interaction, pregunta: str):
    if len(pregunta) > 300:
        await interaction.response.send_message("‚ùå La pregunta es muy larga. M√°ximo 300 caracteres.", ephemeral=True)
        return
    
    await interaction.response.defer()
    
    # Prompt optimizado para respuestas cortas
    quick_prompt = f"Responde de forma extremadamente concisa y directa (m√°ximo 1200 caracteres, s√© breve y ve al punto): {pregunta}"
    
    respuesta = await gemini_mgr.get_response(quick_prompt, max_tokens=250)
    
    # Forzar respuesta corta
    respuesta_corta = ensure_short_response(respuesta, 1500)
    
    # Emoji de rayo para respuestas r√°pidas ‚ö°
    await interaction.followup.send(f"‚ö° {respuesta_corta}")

@bot.tree.command(name="stats", description="Muestra estad√≠sticas del bot")
async def stats(interaction: discord.Interaction):
    await interaction.response.send_message(f"üìä Total de requests: {gemini_mgr.total_requests}")

@bot.tree.command(name="clear", description="Limpia el historial de conversaci√≥n")
async def clear(interaction: discord.Interaction):
    gemini_mgr.chat = gemini_mgr.model.start_chat(history=[])
    await interaction.response.send_message("üßπ Historial de conversaci√≥n limpiado")

# Manejo de errores global
@bot.tree.error
async def on_app_command_error(interaction: discord.Interaction, error):
    if isinstance(error, app_commands.CommandInvokeError):
        await interaction.followup.send("‚ùå Error al procesar el comando. Intenta m√°s tarde.", ephemeral=True)
        print(f"‚ùå Error en comando: {error}")

# EJECUCI√ìN
try:
    bot.run(DISCORD_TOKEN)
except Exception as e:
    print(f"‚ùå Error ejecutando el bot: {e}")